{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07354a8-a512-4b55-9e5b-a982c1cebe52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "# import dask\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import ptitprince as pt\n",
    "# import seaborn as sns\n",
    "import xarray as xr\n",
    "# from scipy import stats\n",
    "\n",
    "import tams\n",
    "from tams.mosa import BASE_DIR, load_wrf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4c9661-6044-4ec5-98ef-77fc22059285",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f823947d-bb2b-497d-8fda-0f68062e02ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = list((BASE_DIR / \"WY2011/WRF\").glob(\"*.nc\"))\n",
    "assert len(all_files) == 365 * 24, \"file for each hour\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb4d4d1-fa6a-4416-afed-ac5c2df8aa1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's just get a subset for faster testing\n",
    "files = sorted((BASE_DIR / \"WY2011/WRF\").glob(\"tb_rainrate_2010-09-??_??:??.nc\"))\n",
    "assert len(files) == 30 * 24\n",
    "files = files[:24 * 3]\n",
    "\n",
    "print(files[0])\n",
    "print(\"...\")\n",
    "print(files[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d538eb-2d59-4321-8af5-d0fe688d6d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "ds = load_wrf(files)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d786df05-8d21-4cbd-b08b-66900f231723",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.ctt.isel(time=0).plot(x=\"lon\", y=\"lat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95551804-1d73-4eaa-8f8a-6f04e4989c8a",
   "metadata": {},
   "source": [
    "## Identify CEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53b70fb-3471-4cca-a72b-162a441f983d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "ce_lists, _ = tams.identify(ds.ctt, parallel=True, ctt_threshold=241, ctt_core_threshold=225)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d203ce-a775-4b1d-9bd3-9bdb9130eb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "ce_lists[5].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ea84c3-153d-429c-87e1-c5326a6efaed",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = ce_lists[5].iloc[0:1]\n",
    "d = ce_lists[6].iloc[0:1]\n",
    "tams.overlap(c, c.translate(xoff=0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851fd9df-00ad-418a-b40b-d24f08a55d9d",
   "metadata": {},
   "source": [
    "## Track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7048f9-1a89-4d2c-8831-0379ac90f5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "ce = tams.track(ce_lists, ds.time.values, overlap_threshold=0.5)\n",
    "ce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820b2561-4760-49f3-ab93-2cefc70ddf72",
   "metadata": {},
   "outputs": [],
   "source": [
    "tams.plot_tracked(ce.query(\"time <= '2010-09-01 07'\"), size=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48fc5847-aa33-4f2f-a5c8-cb366d29c676",
   "metadata": {},
   "source": [
    "## Classify (MCS???)\n",
    "\n",
    "### First add precip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec8f0dc-ba1e-415a-9ffe-309d56bfed34",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# non-parallel method!\n",
    "\n",
    "# dfs = []\n",
    "# for t in ds.time.values:\n",
    "#     df = tams.data_in_contours(ds.pr.sel(time=t), ce.query(\"time == @t\"),\n",
    "#                                merge=True,\n",
    "#                               agg=(\"mean\", \"max\", \"count\"),)\n",
    "#     dfs.append(df)\n",
    "# ce0 = pd.concat(dfs)\n",
    "# ce0.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03baee4e-c82d-48a4-b149-2bedcc756fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def _agg_one(ds_t, g):\n",
    "    df = tams.data_in_contours(ds_t, g, merge=True, agg=(\"mean\", \"max\", \"count\"))\n",
    "    return df\n",
    "    \n",
    "\n",
    "dfs = joblib.Parallel(n_jobs=-2, verbose=10, batch_size=\"auto\")(\n",
    "    joblib.delayed(_agg_one)(ds.pr.sel(time=t), g)\n",
    "    for t, g in ce.drop(columns=[\"mean_pr\", \"max_pr\", \"count_pr\"], errors=\"ignore\").groupby(\"time\")\n",
    ")\n",
    "\n",
    "ce = pd.concat(dfs)\n",
    "ce.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9b1780-4e48-470d-ab8a-d57a2d7c7764",
   "metadata": {},
   "source": [
    "### Now apply criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b3bea0-e73c-4f41-96a0-cff26ced9ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "n = ce.mcs_id.max() + 1\n",
    "is_mcs_list = [None] * n\n",
    "reason_list = [None] * n\n",
    "for mcs_id, g in ce.groupby(\"mcs_id\"):\n",
    "    # Compute time\n",
    "    t = g.time.unique()\n",
    "    tmin = t.min()\n",
    "    tmax = t.max()\n",
    "    duration = pd.Timedelta(tmax - tmin)\n",
    "    \n",
    "    # TODO: collect reasons\n",
    "\n",
    "    # Assuming instantaneous times, need 5 h for the 4 continuous h criteria\n",
    "    # but for accumulated (during previous time step), 4 is fine(?)\n",
    "    n = 4\n",
    "    if duration < pd.Timedelta(f\"{n}H\"):\n",
    "        is_mcs_list[mcs_id] = False\n",
    "        reason_list[mcs_id] = \"duration\"\n",
    "        continue\n",
    "\n",
    "    # Sum area over cloud elements\n",
    "    area = g.groupby(\"itime\")[\"area_km2\"].sum()\n",
    "    \n",
    "    # 1. Assess area criterion\n",
    "    # NOTE: rolling usage assuming data is hourly\n",
    "    yes = (area >= 40_000).rolling(n, min_periods=0).count().eq(n).any()\n",
    "    if not yes:\n",
    "        is_mcs_list[mcs_id] = False\n",
    "        reason_list[mcs_id] = \"area\"\n",
    "        continue\n",
    "\n",
    "    # Agg min precip over cloud elements\n",
    "    maxpr = g.groupby(\"itime\")[\"max_pr\"].max()\n",
    "    \n",
    "    # 2. Assess minimum pixel-peak precip criterion\n",
    "    yes = (maxpr >= 10).rolling(n, min_periods=0).count().eq(n).any()\n",
    "    if not yes:\n",
    "        is_mcs_list[mcs_id] = False\n",
    "        reason_list[mcs_id] = \"peak precip\"\n",
    "        continue\n",
    "    \n",
    "    # Compute rainfall volume\n",
    "    g[\"prvol\"] = g.area_km2 * g.mean_pr  # per CE\n",
    "    prvol = g.groupby(\"itime\")[\"prvol\"].sum()\n",
    "    \n",
    "    # 3. Assess minimum rainfall volume criterion\n",
    "    yes = (prvol >= 20_000).sum() >= 1\n",
    "    if not yes:\n",
    "        is_mcs_list[mcs_id] = False\n",
    "        reason_list[mcs_id] = \"rainfall volume\"\n",
    "        continue\n",
    "    \n",
    "    # 4. Overshoot threshold currently met for all due to TAMS approach\n",
    "    \n",
    "    # If make it to here, is MCS\n",
    "    is_mcs_list[mcs_id] = True\n",
    "    reason_list[mcs_id] = \"\"\n",
    "    \n",
    "assert len(is_mcs_list) == len(reason_list) == ce.mcs_id.max() + 1\n",
    "assert not any(x is None for x in is_mcs_list)\n",
    "assert not any(x is None for x in reason_list)\n",
    "assert (ce.query(\"is_mcs == True\").not_is_mcs_reason == \"\").all()\n",
    "assert (ce.query(\"is_mcs == False\").not_is_mcs_reason != \"\").all()\n",
    "    \n",
    "ce = ce.drop(columns=[\"is_mcs\"], errors=\"ignore\").merge(\n",
    "    pd.Series(is_mcs_list, index=range(len(is_mcs_list)), name=\"is_mcs\"),\n",
    "    how=\"left\", left_on=\"mcs_id\", right_index=True,\n",
    ")\n",
    "ce = ce.drop(columns=[\"not_is_mcs_reason\"], errors=\"ignore\").merge(\n",
    "    pd.Series(reason_list, index=range(len(is_mcs_list)), name=\"not_is_mcs_reason\"),\n",
    "    how=\"left\", left_on=\"mcs_id\", right_index=True,\n",
    ")\n",
    "ce.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5b7e3a-5a96-40f2-bfe6-2d308e96310b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ce.is_mcs.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a151bc-f94c-4499-a8a1-572ce53147f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ce.not_is_mcs_reason.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d96c37-8f07-4fb9-8772-0ebe9e3df8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = ce.query(\"mcs_id == 5\")\n",
    "g"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4d5c14-d1f3-4ab2-a1fb-eefc774bbffa",
   "metadata": {},
   "source": [
    "## Save\n",
    "\n",
    "* We don't need 219 stuff\n",
    "* We don't need all CE coordinates, just centroid (and maybe ellipse params?)\n",
    "* 'itime' and 'dtime' can be re-derived\n",
    "\n",
    "### Clean up table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc688909-8498-4445-8752-411e11b22279",
   "metadata": {},
   "outputs": [],
   "source": [
    "cen = ce.geometry.to_crs(\"EPSG:32663\").centroid.to_crs(\"EPSG:4326\")\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\", category=UserWarning, message=\"ellipse model failed for POLYGON\")\n",
    "    eccen = ce.geometry.apply(tams.calc_ellipse_eccen)\n",
    "\n",
    "col_order = [\n",
    " 'time',\n",
    " 'lat',\n",
    " 'lon',\n",
    " 'area_km2',\n",
    " 'eccen',\n",
    " 'mcs_id',\n",
    " 'mean_pr',\n",
    " 'max_pr',\n",
    " 'count_pr',\n",
    " 'is_mcs',\n",
    " 'not_is_mcs_reason',\n",
    "]\n",
    "\n",
    "ce_ = (\n",
    "    ce\n",
    "    .drop(\n",
    "        columns=[\n",
    "            \"inds219\", \"area219_km2\", \"cs219\",\n",
    "            \"itime\", \"dtime\",\n",
    "            \"geometry\",\n",
    "        ]\n",
    "    )\n",
    "    .assign(eccen=eccen)\n",
    "    .assign(lat=cen.y, lon=cen.x)\n",
    ")\n",
    "\n",
    "assert set(ce_.columns) == set(col_order)\n",
    "\n",
    "df = pd.DataFrame(ce_)[col_order]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b523935e-ee2e-4c37-893a-a1317e0ac552",
   "metadata": {},
   "source": [
    "### Choose filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee2db58-d008-4044-b9fb-e0e4f630cb6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output directory\n",
    "# out_dir = Path(\"./\")\n",
    "out_dir = Path(\"/glade/scratch/knocasio/SAAG\")\n",
    "\n",
    "# noclobber = False  # overwrite\n",
    "noclobber = True  # don't\n",
    "\n",
    "# Filename based on times\n",
    "ta, tb = pd.Timestamp(ds.time.values[0]), pd.Timestamp(ds.time.values[-1])\n",
    "tfmt = f\"%Y%m%d%H\"\n",
    "ofn_stem_desired = f\"ce_{ta:{tfmt}}-{tb:{tfmt}}\"\n",
    "ofp = out_dir / f\"{ofn_stem_desired}.csv.gz\"\n",
    "\n",
    "# Adjust if already exists so don't overwrite\n",
    "if noclobber:\n",
    "    i = 0\n",
    "    while ofp.is_file():\n",
    "        i += 1\n",
    "        ofp = out_dir / f\"{ofn_stem_desired}_{i}.csv.gz\"\n",
    "\n",
    "print(ofp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea71a55-fb1a-47b8-a55f-1d6d0425c627",
   "metadata": {},
   "source": [
    "### Write out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d245c6f0-428c-480e-b2cb-6fa97f39b9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(ofp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mambaforge-tams-dev]",
   "language": "python",
   "name": "conda-env-mambaforge-tams-dev-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
